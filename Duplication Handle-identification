
# Load your data
file_path = "C:/path_to_your_file.csv"  # Replace with your actual file path
df = pd.read_csv(file_path)

# Check for duplicates
duplicates = df[df.duplicated(keep=False)]

# Count duplicates
if not duplicates.empty:
    duplicate_count = duplicates.groupby(duplicates.columns.tolist()).size().reset_index(name='count')
    print(duplicate_count)
else:
    print("No duplicate rows found.")

Output
No duplicate rows found.


Data set-1
person_home_ownership	person_emp_length	loan_intent	loan_grade	loan_amnt	loan_int_rate	loan_percent_income	cb_person_default_on_file	cb_person_cred_hist_length	loan_status
RENT	0	EDUCATION	B	6000	11.49	0.17	N	14	0
RENT	0	EDUCATION	B	6000	11.49	0.17	N	14	0

OutPut

 id  person_age  person_income person_home_ownership  person_emp_length  \
0   0          37          35000                  RENT                  0   

  loan_intent loan_grade  loan_amnt  loan_int_rate  loan_percent_income  \
0   EDUCATION          B       6000          11.49                 0.17   

  cb_person_default_on_file  cb_person_cred_hist_length  loan_status  count  
0                         N                          14            0      2  
